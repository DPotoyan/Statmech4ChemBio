

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Entropy and Information &#8212; Statistical Mechanics for Chemistry and Biology</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=5b4479735964841361fd" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=5b4479735964841361fd" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=5b4479735964841361fd" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd" />
  <script src="../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=5b4479735964841361fd"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script type="application/vnd.jupyter.widget-state+json">{"state": {"3b277779031a4427b153279bc74df361": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "769e9b2690da4540a71b62d8e3195863": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "2aea4e3d020943b29526a5890103136a": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "FloatSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "\u03bc1", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_3b277779031a4427b153279bc74df361", "max": 3.0, "min": -3.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_769e9b2690da4540a71b62d8e3195863", "tabbable": null, "tooltip": null, "value": 0.0}}, "7cdf83a0ddd34ef4a8179739888105e0": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "84012884a415489394ede8a6e7005136": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "94ea455b2ed24bc69db689dbe4dcd6d8": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "FloatSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "\u03c31", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_7cdf83a0ddd34ef4a8179739888105e0", "max": 3.0, "min": 0.1, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_84012884a415489394ede8a6e7005136", "tabbable": null, "tooltip": null, "value": 1.0}}, "fec4f6b191ca4728bb76501f7c3b28bc": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "96ce78d2969349a587f8d39e4d0cb926": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "e062d769df4b48338c726191bcb33a77": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "FloatSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "\u03bc2", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_fec4f6b191ca4728bb76501f7c3b28bc", "max": 3.0, "min": -3.0, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_96ce78d2969349a587f8d39e4d0cb926", "tabbable": null, "tooltip": null, "value": 1.0}}, "a709cc2272e644eeb273b7218a06dce2": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "b05e8d3115994a199fac1c22483e1bc4": {"model_name": "SliderStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "SliderStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "StyleView", "description_width": "", "handle_color": null}}, "abc6d1f46cf744e791fb2f59646501a1": {"model_name": "FloatSliderModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "FloatSliderModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "FloatSliderView", "behavior": "drag-tap", "continuous_update": true, "description": "\u03c32", "description_allow_html": false, "disabled": false, "layout": "IPY_MODEL_a709cc2272e644eeb273b7218a06dce2", "max": 3.0, "min": 0.1, "orientation": "horizontal", "readout": true, "readout_format": ".2f", "step": 0.1, "style": "IPY_MODEL_b05e8d3115994a199fac1c22483e1bc4", "tabbable": null, "tooltip": null, "value": 2.0}}, "b28dc7c0d88b496e8288fb69ff754051": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "6d369e87d6774eb2acae7bc8567a47af": {"model_name": "VBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "2.0.0", "state": {"_dom_classes": ["widget-interact"], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "2.0.0", "_model_name": "VBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "2.0.0", "_view_name": "VBoxView", "box_style": "", "children": ["IPY_MODEL_2aea4e3d020943b29526a5890103136a", "IPY_MODEL_94ea455b2ed24bc69db689dbe4dcd6d8", "IPY_MODEL_e062d769df4b48338c726191bcb33a77", "IPY_MODEL_abc6d1f46cf744e791fb2f59646501a1", "IPY_MODEL_47337c2734a946708e87a0f41bd8155a"], "layout": "IPY_MODEL_b28dc7c0d88b496e8288fb69ff754051", "tabbable": null, "tooltip": null}}, "dd0273bc20034029b23ac83b464e28fb": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "2.0.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "2.0.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "2.0.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border_bottom": null, "border_left": null, "border_right": null, "border_top": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "47337c2734a946708e87a0f41bd8155a": {"model_name": "OutputModel", "model_module": "@jupyter-widgets/output", "model_module_version": "1.0.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/output", "_model_module_version": "1.0.0", "_model_name": "OutputModel", "_view_count": null, "_view_module": "@jupyter-widgets/output", "_view_module_version": "1.0.0", "_view_name": "OutputView", "layout": "IPY_MODEL_dd0273bc20034029b23ac83b464e28fb", "msg_id": "", "outputs": [{"output_type": "display_data", "metadata": {}, "data": {"text/plain": "<Figure size 800x600 with 1 Axes>", "image/png": "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"}}], "tabbable": null, "tooltip": null}}}, "version_major": 2, "version_minor": 0}</script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script crossorigin="anonymous" data-jupyter-widgets-cdn="https://cdn.jsdelivr.net/npm/" src="https://cdn.jsdelivr.net/npm/@jupyter-widgets/html-manager@1.0.6/dist/embed-amd.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '1_stats/Entropy';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Thermodynamics" href="../2_thermo/intro.html" />
    <link rel="prev" title="Diffusion" href="Diffusion.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.jpg" class="logo__image only-light" alt="Statistical Mechanics for Chemistry and Biology - Home"/>
    <script>document.write(`<img src="../_static/logo.jpg" class="logo__image only-dark" alt="Statistical Mechanics for Chemistry and Biology - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../index.html">
                    About
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Chapters</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../schedule.html">Schedule (Spring 2025)</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="intro.html">Stats</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Probabilities_Counting.html">Probability theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="Random_Variables.html">Random variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="Diffusion.html">Diffusion</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Entropy and Information</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../2_thermo/intro.html">Thermodynamics</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2_thermo/01_Thermo.html">Review of thermodynamics principles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2_thermo/02_FreeEnergies.html">Thermodynamic Potentials</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3_ensembles/intro.html">Ensembles</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../3_ensembles/nve.html">Intro to Statistical Ensembles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3_ensembles/nvt.html">Ensembles in phase-space</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3_ensembles/npt.html">Open Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="../3_ensembles/ensemble_overview.html">Summary of Ensembles</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_ising/intro.html">Phase transitions</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_ising/00_MC.html">Monte Carlo and the power of randomness</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_ising/01_MCMC.html">Ising models and Metropolis algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_ising/02_phase_tranistions.html">Phase transitions through the lense of Ising models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_ising/03_MeanField.html">Mean Field Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_ising/03_vdw.html">Mean Field theory of interacting fluids</a></li>





<li class="toctree-l2"><a class="reference internal" href="../4_ising/04_analytic.html">Analytic solutions to 1D Ising model</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../5_fluids/intro.html">Fluids</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../5_fluids/Intro2Fluids.html">Statistical mechanics of fluids</a></li>
<li class="toctree-l2"><a class="reference internal" href="../5_fluids/mc_lj.html">MC simulations of fluids</a></li>

<li class="toctree-l2"><a class="reference internal" href="../5_fluids/Intro2MD.html">Molecular Dynamics</a></li>

<li class="toctree-l2"><a class="reference internal" href="../5_fluids/md_lj.html">MD simulations of fluids</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../6_kinetics/intro.html">Kinetics</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../6_kinetics/langevin.html">Langevin equation and Brownian motion</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/py-lab/intro.html">Python</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/py-lab/intro2py.html">Python3</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/py-lab/intro2numpy.html">NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/py-lab/intro2viz.html">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/py-lab/python_OOP_challenge.html">Tutorial: Building Python Classes</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/np-lab/intro.html">Numpy lab</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/np-lab/np_prob.html">Numpy and Probabilities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/np-lab/sinc_function.html">Numpy Lab: Sinc Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/np-lab/linear_functions.html">Numpy Lab: Linear Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/np-lab/1d_gas_sim.html">Tutorial: Numpy simultions of 1D gas</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/np-lab/2d_gas_sim.html">Tutorial: Numpy simultions of 2D gas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/rw-lab/intro.html">Random Walks</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/rw-lab/rw_lab.html">Random walk simulations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/rw-lab/InverseTransform.html">The Inverse Transform of RVs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/rw-lab/change_rv_jax.html">Change of variables with automatic differentiation (autodiff)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/rw-lab/polymer-conf.html">Conformations of Random Polymer Chains</a></li>

<li class="toctree-l2"><a class="reference internal" href="../labs/rw-lab/langevin.html">Langevin Equation for Brownian Motion and Mean Square Displacement (MSD)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/lab4/intro.html">Application of ensembles</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab4/nvt_application.html">Free energy and protein folding</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab4/TwoState.html">Two-state system</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab4/mass_action.html">Mass action law</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/lab5/intro.html">Simulating Ising models</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab5/torch_ising.html">Ising-2D simulations using ML libraries</a></li>



<li class="toctree-l2"><a class="reference internal" href="../labs/lab5/Wolf.html">Other Methods for sampling Ising models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab5/enhance-sampling.html">Non-boltzman (enhanced) sampling ideas</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../labs/lab6/intro.html">Simulating Fluids</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab6/openmm_double_well.html">Double Well potential using OpenMM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab6/openmm_lj_chain.html">Simulating toy polymers using openMM</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab6/openmm_ethane.html">Simulating Ethane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../labs/lab6/openmm_villin.html">Simulating solvated protein</a></li>
</ul>
</li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/DPotoyan/Statmech4ChemBio/master?urlpath=lab/tree/1_stats/Entropy.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://colab.research.google.com/github/DPotoyan/Statmech4ChemBio/blob/master/1_stats/Entropy.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/1_stats/Entropy.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Entropy and Information</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#surprise">Surprise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#addititivity-of-information">Addititivity of Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-bit-base-two">Why bit (base two)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shannon-entropy-and-information">Shannon Entropy and Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-micro-and-macro-states">Entropy, micro and macro states</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretations-of-entropy">Interpretations of Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-as-a-measure-of-information">1. Entropy as a Measure of Information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-as-a-measure-of-uncertainty">2. Entropy as a Measure of Uncertainty</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#physical-and-thermodynamic-implications">3. Physical and Thermodynamic Implications</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-information-physical">Is Information Physical?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-entropy-maxent-principle">Maximum Entropy (MaxEnt) Principle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-maxent-biased-die-example">Application MaxEnt: Biased Die Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy">Relative Entropy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assymetry-of-kl-and-irreversibility">Assymetry of KL and irreversibility</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy-in-machine-learning">Relative Entropy in Machine learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems">Problems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-compute-entropy-for-gas-partitioning">Problem-1: Compute Entropy for gas partitioning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2">Problem-2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-gambling-with-ten-sided-die">Problem-3: Gambling with ten sided die</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-biased-random-walker-in-2d">Problem-3 Biased Random walker in 2D</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5-arrow-of-time-in-2d-diffusion">Problem-5: Arrow of time in 2D diffusion</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="entropy-and-information">
<h1>Entropy and Information<a class="headerlink" href="#entropy-and-information" title="Permalink to this heading">#</a></h1>
<div class="admonition-what-you-will-learn admonition">
<p class="admonition-title"><strong>What you will learn</strong></p>
<ul class="simple">
<li><p>Entropy is a measure of information or uncertainty, quantified using probability distributions.</p></li>
<li><p>When expressed in <span class="math notranslate nohighlight">\(\log_2\)</span>, entropy represents the number of binary (yes/no) questions needed to identify a microstate within a macrostate.</p></li>
<li><p>Entropy quantifies the diversity of microstates, reaching its maximum for a uniform (flat) distributions.</p></li>
<li><p>The Maximum Entropy (MaxEnt) principle provides the most unbiased way to infer probability distributions given empirical constraints.</p></li>
<li><p>In MaxEnt Entropy what we are maximizing is Relative Entropy with respect to reference system where all microstates are equally probable.</p></li>
<li><p>Relative entropy quantifies the information lost when approximating one probability distribution with another.</p></li>
<li><p>Relative entropy also shows that information (or uncertainty) tends to increase irreversibly in the absence of external interventions.</p></li>
<li><p>Relative entropy encodes statistical Distinguishability between forwrad and reverse processes known as the thermodynamic arrow of time.</p></li>
</ul>
</div>
<section id="surprise">
<h2>Surprise<a class="headerlink" href="#surprise" title="Permalink to this heading">#</a></h2>
<p><strong>Which of these two statements conveys the most information?</strong></p>
<ul class="simple">
<li><p>I will eat some food tomorrow.</p></li>
<li><p>I will see a giraffe walking by my apartment.</p></li>
</ul>
<p><strong>A measure of information (whatever it may be) is closely related to the element of surprise!</strong></p>
<ul class="simple">
<li><p>has very high probability and so conveys little information,</p></li>
<li><p>has very low probability and so conveys much information.</p></li>
</ul>
<blockquote>
<div><p>If we quanitfy suprise we will quantify information</p>
</div></blockquote>
</section>
<section id="addititivity-of-information">
<h2>Addititivity of Information<a class="headerlink" href="#addititivity-of-information" title="Permalink to this heading">#</a></h2>
<p><strong>Knowledge leads to gaining information</strong></p>
<p>Which is more surprising (contains more information)?</p>
<ul class="simple">
<li><p>E1: The card is heart? <span class="math notranslate nohighlight">\(P(E_1) = \frac{1}{4}\)</span></p></li>
<li><p>E2:The card is Queen? <span class="math notranslate nohighlight">\(P(E_2)  =  \frac{4}{52} = \frac{1}{13}\)</span></p></li>
<li><p>E3: The card is Queen of hearts? <span class="math notranslate nohighlight">\(P(E_1 \, and\,  E_2) = \frac{1}{52}\)</span></p></li>
</ul>
<p><strong>Knowledge of event should add up our information: <span class="math notranslate nohighlight">\(I(E) \geq 0\)</span></strong></p>
<ol class="arabic simple">
<li><p>We learn the card is heart <span class="math notranslate nohighlight">\(I(E_1)\)</span></p></li>
<li><p>We learn the card is Queen <span class="math notranslate nohighlight">\(I(E_2)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(I(E_1 and E_2) = I(E_1) + I(E_2)\)</span></p></li>
</ol>
<p><strong>A logarithm of probability is a good candidate function for information!</strong></p>
<div class="math notranslate nohighlight">
\[log_2 P(E_1) P(E_2) = log_2 P(E_1) + log_2(E_2)\]</div>
<ul class="simple">
<li><p>What about the sign?</p></li>
</ul>
<div class="math notranslate nohighlight">
\[I_i = -log_2 p_i\]</div>
</section>
<section id="why-bit-base-two">
<h2>Why bit (base two)<a class="headerlink" href="#why-bit-base-two" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Consider symmetric a 1D random walk with equal jump probabilities. We can view <strong>Random walk = string of Yes/No questions</strong>.</p></li>
<li><p>Imagine driving to a location how many left/right turn informations you need to reach destination?</p></li>
<li><p>You gain one bit of information when you are told Yes/No answer</p></li>
</ul>
<div class="math notranslate nohighlight">
\[I(X=0) = I(X=1) = -log_2 \frac{1}{2} = 1\]</div>
<ul class="simple">
<li><p>To decode N step random walk trajectory we need N bits.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(x_0,x_1,...x_N) = 10111101001010100100\]</div>
</section>
<section id="shannon-entropy-and-information">
<h2>Shannon Entropy and Information<a class="headerlink" href="#shannon-entropy-and-information" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>If we want to understand the overall uncertainty in the system, we need to consider all possible outcomes weighted by their probability of occurrence.</p></li>
<li><p>This means that rather than looking at the surprise of a single event, <strong>we consider the average surprise one would experience over many trials drawn from <span class="math notranslate nohighlight">\(p\)</span>.</strong></p></li>
<li><p>Thus, we take the expectation of surprise over the entire distribution <span class="math notranslate nohighlight">\(\langle -log p \rangle\)</span> arriving at a formula known as Shaonons expression of Entropy.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title"><strong>Shanon Entropy</strong></p>
<div class="math notranslate nohighlight">
\[S = -\sum_i p_i log_2 p_i\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\)</span> Entropy(Information) measured in bits</p></li>
<li><p><span class="math notranslate nohighlight">\(p_i\)</span> probability of microstate <span class="math notranslate nohighlight">\(i\)</span>, e.g coin flip or die roll outcomes</p></li>
</ul>
</div>
<ul class="simple">
<li><p>One often uses <span class="math notranslate nohighlight">\(H\)</span> to denote Shanon Entropy (<span class="math notranslate nohighlight">\(log_2\)</span>) and letter <span class="math notranslate nohighlight">\(S\)</span> with <span class="math notranslate nohighlight">\(log_e\)</span> for entropy in units of Boltzman constant <span class="math notranslate nohighlight">\(k_B\)</span></p></li>
<li><p>For now lets just roll with <span class="math notranslate nohighlight">\(k_B=1\)</span> we wont be doing any thermodynamics in here.</p></li>
<li><p>John von Neumann advice to [To Calude Shanon], You should call it Entropy, for two reasons. In the first place you uncertainty function has been used in statistical mechanics under that name. In the second place, and more importantly, no one knows what entropy really is, so in a debate you will always have the advantage.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="k">def</span><span class="w"> </span><span class="nf">binary_entropy</span><span class="p">(</span><span class="n">p</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the binary Shannon entropy for a given probability p.</span>
<span class="sd">    Avoid issues with log(0) by ensuring p is never 0 or 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">p</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">-</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">)</span>

<span class="c1"># Generate probability values, avoiding the endpoints to prevent log(0)</span>
<span class="n">p_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">H_vals</span> <span class="o">=</span> <span class="n">binary_entropy</span><span class="p">(</span><span class="n">p_vals</span><span class="p">)</span>

<span class="c1"># Create a figure with two subplots side-by-side</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>

<span class="c1"># Plot 1: Binary Shannon Entropy Function</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">p_vals</span><span class="p">,</span> <span class="n">H_vals</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;midnightblue&#39;</span><span class="p">,</span>
           <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;$H(p)=-p\log_2(p)-(1-p)\log_2(1-p)$&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;Probability $p$)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Entropy (bits)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Binary Shannon Entropy&quot;</span><span class="p">,</span>  <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Plot 2: Example Distributions and Their Entropy</span>
<span class="c1"># Define a few example two-outcome distributions:</span>
<span class="n">distributions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Uniform (0.5, 0.5)&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">],</span>
    <span class="s2">&quot;Skewed (0.8, 0.2)&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="s2">&quot;Extreme (0.99, 0.01)&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.99</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">]</span>
<span class="p">}</span>

<span class="c1"># Colors for each distribution</span>
<span class="n">colors</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;skyblue&quot;</span><span class="p">,</span> <span class="s2">&quot;salmon&quot;</span><span class="p">,</span> <span class="s2">&quot;lightgreen&quot;</span><span class="p">]</span>

<span class="c1"># For visual separation, use offsets for the bars</span>
<span class="n">width</span> <span class="o">=</span> <span class="mf">0.25</span>
<span class="n">x_ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># positions for the two outcomes</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="n">probs</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">distributions</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="c1"># Compute the Shannon entropy for the distribution</span>
    <span class="n">entropy_val</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log2</span><span class="p">(</span><span class="n">probs</span><span class="p">))</span>
    <span class="c1"># Offset x positions for clarity</span>
    <span class="n">x_positions</span> <span class="o">=</span> <span class="n">x_ticks</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">width</span> <span class="o">-</span> <span class="n">width</span>
    <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x_positions</span><span class="p">,</span> <span class="n">probs</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
              <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">label</span><span class="si">}</span><span class="se">\n</span><span class="s2">Entropy = </span><span class="si">{</span><span class="n">entropy_val</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> bits&quot;</span><span class="p">)</span>
    
<span class="c1"># Set labels and title for the bar plot</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">x_ticks</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticklabels</span><span class="p">([</span><span class="s2">&quot;Outcome 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Outcome 2&quot;</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Example Distributions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;y&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/e7cf3ffc3c37cf204816778fddcb2afbfdf184c7dc4d8f34e2caf39894a622ee.png" src="../_images/e7cf3ffc3c37cf204816778fddcb2afbfdf184c7dc4d8f34e2caf39894a622ee.png" />
</div>
</div>
<ul class="simple">
<li><p>To reiterate once again from Shannon formula <span class="math notranslate nohighlight">\(S=\sum_i -p_ilogp_i\)</span> we see clearly that Entropy is a statistical quantity characterized by the probability distribution over all possibilities.</p></li>
<li><p>The more uncertain (unpredictable) the outcome the higher the entropy of the probability distribution that generates it.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">stats</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib</span>


<span class="c1"># Create figure and axes</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="c1"># Define x range</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

<span class="c1"># Define different distributions</span>
<span class="n">distributions</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Flat (Uniform)&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">loc</span><span class="o">=-</span><span class="mf">2.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
    <span class="s2">&quot;Gaussian (Normal)&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
    <span class="s2">&quot;Narrow Gaussian&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="s2">&quot;Exponential&quot;</span><span class="p">:</span> <span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1"># Plot distributions and annotate entropy</span>
<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">dist</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">distributions</span><span class="o">.</span><span class="n">items</span><span class="p">()):</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
    
    <span class="c1"># Compute differential entropy</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="p">(</span><span class="n">pdf</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Entropy: </span><span class="si">{</span><span class="n">entropy</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">ha</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="c1"># Adjust layout and show plot</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/55251b65d9aee8ab9896c1b7fe5898a25e46e8485a8fa2d6e23bbce818fa1885.png" src="../_images/55251b65d9aee8ab9896c1b7fe5898a25e46e8485a8fa2d6e23bbce818fa1885.png" />
</div>
</div>
<div class="note dropdown admonition">
<p class="admonition-title"><strong>Exercise: Information per letter <span class="math notranslate nohighlight">\(I(m)\)</span> to decode the message</strong> </p>
<ul>
<li><p>Let <span class="math notranslate nohighlight">\(m\)</span>  represent the letters in an alphabet. For example:</p>
<ul class="simple">
<li><p><strong>Korean:</strong> 24 letters</p></li>
<li><p><strong>English:</strong> 26 letters</p></li>
<li><p><strong>Russian:</strong> 33 letters</p></li>
</ul>
</li>
<li><p>The information content associated with these alphabets satisfies:</p>
<div class="math notranslate nohighlight">
\[
  I(\text{Russian}) &gt; I(\text{English}) &gt; I(\text{Korean})
  \]</div>
</li>
<li><p>The information of a sequence of letters is additive, regardless of the order in which they are transmitted:</p>
<div class="math notranslate nohighlight">
\[
  I(m_1, m_2) = I(m_1) + I(m_2)
  \]</div>
</li>
<li><p><strong>Question</strong> If the symbols of English alphabet (+ blank) appear equally probably, what is the information carried by a single symbol? This must be <span class="math notranslate nohighlight">\(log_2(26 + 1) = 4.755\)</span> bits, but for actual English sentences, it is known to be about <strong><span class="math notranslate nohighlight">\(1.3\)</span> bits. Why?</strong></p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<strong>Solution</strong><div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">Not every letter has equal probability or frequency of appearing in a sentence!</p></li>
</ul>
</div>
</details></div>
<div class="note dropdown admonition">
<p class="admonition-title"><strong>Exercise: entropy of die rolls</strong> </p>
<ul class="simple">
<li><p>How much knowledge we need to find out outcome of fair dice?</p></li>
<li><p>We are told die shows a digit higher than 2 (3, 4, 5 or 6). How much knowledge does this information carry?</p></li>
</ul>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<strong>Solution</strong><div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H(E_1) = log_2 6\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H(E_1) - H(E_2) = log_2 6 - log_2 4\)</span></p></li>
</ul>
</div>
</details></div>
<div class="note dropdown admonition">
<p class="admonition-title"><strong>Exercise: Two cats</strong> </p>
<p>There are two kittens. We are told that at least one of them is a male. What is the information we get from this message?</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<strong>Solution</strong><div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<div class="math notranslate nohighlight">
\[E_1 = \{mm,mf,fm, ff \} \]</div>
<div class="math notranslate nohighlight">
\[E_2 = \{mm,mf,fm\}\]</div>
<div class="math notranslate nohighlight">
\[H(E_1) -H(E_2) = log_2 4 -log_2 3 = 0.41\]</div>
</div>
</details></div>
<div class="note dropdown admonition">
<p class="admonition-title"><strong>Exercise: Monty Hall problem</strong> </p>
<p>There are five boxes, of which one contains a prize. A game participant is asked to choose one box. After they choose one of the five boxes, the coordinator of the game identifies as empty three of the four unchosen boxes. What is the information of this message?</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<strong>Solution</strong><div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H(E_1) = log_2 5 = 2.322\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H(E_2) = -\frac{1}{5} log_2 5 - \frac{4}{5} log_2 \frac{4}{5} = 0.722\)</span></p></li>
<li><p class="sd-card-text"><span class="math notranslate nohighlight">\(H(E_1)-H(E_2) = 1.6\)</span></p></li>
</ul>
</div>
</details></div>
<div class="note dropdown admonition">
<p class="admonition-title"><strong>Exercise: Why are there non-integer number of YES/NO questions??</strong> </p>
<p>Explain the origin of the non-integer information. Why it takes less than one-bit to encode information?</p>
<details class="sd-sphinx-override sd-dropdown sd-card sd-mb-3">
<summary class="sd-summary-title sd-card-header">
<strong>Solution</strong><div class="sd-summary-down docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-down" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M5.22 8.72a.75.75 0 000 1.06l6.25 6.25a.75.75 0 001.06 0l6.25-6.25a.75.75 0 00-1.06-1.06L12 14.44 6.28 8.72a.75.75 0 00-1.06 0z"></path></svg></div>
<div class="sd-summary-up docutils">
<svg version="1.1" width="1.5em" height="1.5em" class="sd-octicon sd-octicon-chevron-up" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M18.78 15.28a.75.75 0 000-1.06l-6.25-6.25a.75.75 0 00-1.06 0l-6.25 6.25a.75.75 0 101.06 1.06L12 9.56l5.72 5.72a.75.75 0 001.06 0z"></path></svg></div>
</summary><div class="sd-summary-content sd-card-body docutils">
<ul class="simple">
<li><p class="sd-card-text">We have encountered a fraction of bit of information several times now. What does it imply in terms of number of YES/NO questions. That is becasue in some cases single YES/NO question can rule out more than one elementary event.</p></li>
<li><p class="sd-card-text">In other words we can ask clever questions that can get us to answer faster than doing YES/No on every single possibility</p></li>
<li><p class="sd-card-text">999 blue balls and 1 red ball. how many questions we need to ask to determin the colors of all balls? <span class="math notranslate nohighlight">\(S = 9.97\)</span> bit or 0.01 bit per ball. Divide the container by 500 and 500 and ask where the red ball is? 1 questions rules out 500 balls at once.</p></li>
</ul>
</div>
</details></div>
</section>
<section id="entropy-micro-and-macro-states">
<h2>Entropy, micro and macro states<a class="headerlink" href="#entropy-micro-and-macro-states" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>When all <span class="math notranslate nohighlight">\(\Omega\)</span> number of microstates of the system have equal probability <span class="math notranslate nohighlight">\(p_i=\frac{1}{\Omega}\)</span> the entropy of the system is:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[S= -\sum \frac{1}{\Omega} log \frac{1}{\Omega} = -\Omega \cdot  \frac{1}{\Omega} log \frac{1}{\Omega} = log\Omega\]</div>
<ul class="simple">
<li><p>We arrive at an expression of Entropy first obtained by Boltzmann where thermal energy units (Boltzmans) constant were used.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title"><strong>Entropy expression for equally probable microstates</strong></p>
<div class="math notranslate nohighlight">
\[S(\Omega) = k_B log \Omega\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\Omega\)</span> <strong>Number of Microsates availible to the system</strong></p></li>
<li><p><span class="math notranslate nohighlight">\(k_B\)</span> Boltzmanns constant.</p></li>
</ul>
</div>
<ul class="simple">
<li><p><strong>Entropy for a macrostate A</strong> which has <span class="math notranslate nohighlight">\(\Omega(A)\)</span> number of microstates can be written in terms of macrostate probability</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(A) = \frac{\Omega(A)}{\Omega}\]</div>
<div class="math notranslate nohighlight">
\[S(A) = log \Omega(A) = log P(A) + const\]</div>
<ul class="simple">
<li><p>Entropy of a macrostate <strong>quantifies how probable that macrostate is!</strong>. This is yet another manifestation of Large Deviation Theorem we encountered before</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(A) \sim e^{S(A)}\]</div>
<div class="tip dropdown admonition">
<p class="admonition-title"><strong>Flashback to Random Walk, Binomial, and Large Deviation Theorem</strong>  </p>
<ul class="simple">
<li><p><a class="reference external" href="https://dpotoyan.github.io/Statmech4ChemBio/1_stats/Probabilities_Counting.html#large-deviation-theory">Where have we seen the entropy expression before?</a></p></li>
<li><p>When we took the <strong>log of the binomial distribution</strong>! But why did we call it entropy?</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
S(n) = \log \frac{N!}{n! (N-n)!} = N \left[ - f \log f - (1-f) \log (1-f) \right] = N s(f)
\]</div>
<ul>
<li><p>Here, <span class="math notranslate nohighlight">\( f = n/N \)</span> represents the <strong>fraction (empirical probability) of steps to the right</strong> in a random walk.</p></li>
<li><p><span class="math notranslate nohighlight">\( s(f) = S/N \)</span> is the <strong>entropy per particle (or per step)</strong>, while <span class="math notranslate nohighlight">\( S \)</span> is the <strong>total entropy</strong>.</p></li>
<li><p><strong>Different macrostates have different entropy, depending on the number of microstates they contain!</strong></p>
<div class="math notranslate nohighlight">
\[
  P(n) = \frac{\Omega(n)}{\Omega_{\text{total}}} =  \frac{N!}{n! (N-n)!} \cdot \frac{1}{2^N}
  \]</div>
</li>
<li><p>where <span class="math notranslate nohighlight">\( \Omega_{\text{total}} = 2^N \)</span> is the <strong>total number of microstates</strong>.</p></li>
<li><p>Once again, we can think of <strong>the entropy of a macrostate as being related to its probability:</strong></p>
<div class="math notranslate nohighlight">
\[
  S(f) \sim \log P(f)
  \]</div>
</li>
</ul>
<p><strong>Connection to the Large Deviation Theorem</strong><br />
When we express probability in terms of entropy, we recover the <strong>Large Deviation Theorem</strong>, which states that <strong>fluctuations from the most likely macrostates are exponentially suppressed</strong>:</p>
<div class="math notranslate nohighlight">
\[
P(f) \sim e^{N s(f)}
\]</div>
<p>This result highlights how entropy naturally governs the likelihood of macrostates in statistical mechanics.</p>
</div>
</section>
<section id="interpretations-of-entropy">
<h2>Interpretations of Entropy<a class="headerlink" href="#interpretations-of-entropy" title="Permalink to this heading">#</a></h2>
<section id="entropy-as-a-measure-of-information">
<h3>1. Entropy as a Measure of Information<a class="headerlink" href="#entropy-as-a-measure-of-information" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Entropy quantifies the amount of information needed to specify the exact microstate of a system.</p></li>
<li><p>This can be understood as the number of yes/no (binary) questions required to identify a specific microstate.</p></li>
<li><p>Examples:</p>
<ul>
<li><p>Determining the exact trajectory of an <span class="math notranslate nohighlight">\(N\)</span>-step random walk.</p></li>
<li><p>Identifying the detailed molecular distribution of gas particles in a container.</p></li>
</ul>
</li>
</ul>
</section>
<section id="entropy-as-a-measure-of-uncertainty">
<h3>2. Entropy as a Measure of Uncertainty<a class="headerlink" href="#entropy-as-a-measure-of-uncertainty" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A more <strong>uniform (flat) probability distribution</strong> of microstates corresponds to <strong>higher entropy</strong>, whereas a <strong>more concentrated (narrow) distribution</strong> leads to <strong>lower entropy</strong>.</p></li>
<li><p><strong>Higher entropy</strong> implies <strong>greater uncertainty</strong> about microstates.</p>
<ul>
<li><p>In a high-entropy system, identifying the exact microstate is much harder.</p></li>
<li><p>In contrast, a low-entropy system is more predictable, as fewer microstates are accessible.</p></li>
</ul>
</li>
<li><p>When all microstates are equally probable, entropy simplifies to be just the logarithm of the number of microstates, <span class="math notranslate nohighlight">\(S = k_B \log \Omega\)</span>.</p></li>
<li><p>A system will naturally tend to evolve toward macrostates with higher entropy because they correspond to a larger number of available microstates, making them statistically more likely.</p></li>
</ul>
</section>
<section id="physical-and-thermodynamic-implications">
<h3>3. Physical and Thermodynamic Implications<a class="headerlink" href="#physical-and-thermodynamic-implications" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Systems with high entropy have a vast number of possible microstates, meaning more work is neededin an informational senseto pinpoint a specific one.</p></li>
<li><p><strong>Reducing entropy requires physical work:</strong></p>
<ul>
<li><p>Example: To reduce the number of yes/no questions needed to specify the position of gas molecules, one must compress the gas, which requires energy.</p></li>
</ul>
</li>
<li><p><strong>Spontaneous and irreversible processes tend to increase entropy:</strong></p>
<ul>
<li><p>Entropy naturally increases in isolated systems because evolution toward more probable (higher entropy) macrostates is statistically favored.</p></li>
<li><p>This principle underlies the <strong>Second Law of Thermodynamics</strong>, which states that entropy never decreases in a closed system.</p></li>
</ul>
</li>
</ul>
</section>
</section>
<section id="is-information-physical">
<h2>Is Information Physical?<a class="headerlink" href="#is-information-physical" title="Permalink to this heading">#</a></h2>
<figure class="align-default" id="markdown-fig">
<img alt="diffflux" src="../_images/max-dem.png" />
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Maxwells demon controlling the door that allows the passage of single molecules from one side to the other. The initial hot gas gets hotter at the end of the process while the cold gas gets colder.</span><a class="headerlink" href="#markdown-fig" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><strong>Wheelers It from Bit:</strong></p>
<ul>
<li><p>Every it  every particle, every field, every force, and even the fabric of space-time  derives its function, meaning, and very existence from binary answers to yes-or-no questions. In essence, Wheelers idea of It from Bit posits that at the most fundamental level, the physical universe is rooted in information. This perspective implies that all aspects of reality are ultimately information-theoretic in origin.</p></li>
</ul>
</li>
<li><p><strong>Maxwells Demon:</strong></p>
<ul>
<li><p>Maxwells Demon is a thought experiment that challenges the second law of thermodynamics by envisioning a tiny being capable of sorting molecules based on their speeds. By selectively allowing faster or slower molecules to pass through a gate, the demon appears to reduce entropy without expending energy. However, the act of gathering and processing information incurs a thermodynamic cost, ensuring that the overall entropy balance is maintained. This paradox underscores that information is a physical quantity with measurable effects on energy and entropy.</p></li>
</ul>
</li>
</ul>
</section>
<section id="maximum-entropy-maxent-principle">
<h2>Maximum Entropy (MaxEnt) Principle<a class="headerlink" href="#maximum-entropy-maxent-principle" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Probability represents our incomplete information. Given partial knowledge about some variables how should we construct a probability distribution that is unbiased beyond what we know?</p></li>
<li><p>The <strong>Maximum Entropy (MaxEnt) Principle</strong> provides the best approach: we choose probabilities to <strong>maximize Shannon entropy</strong> while satisfying given constraints.</p></li>
<li><p>This ensures the least biased probability distribution possible, consistent with the available information.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
S = - \sum_k p_k \log p_k.
\]</div>
<ul class="simple">
<li><p>We seek to maximize <span class="math notranslate nohighlight">\( S(p) \)</span> subject to the constraints:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sum_k p_k = 1, \quad \sum_k p_k \, x_k = \langle x \rangle, \quad \sum_k p_k \, y_k = \langle y^b \rangle, \quad \text{etc.}
\]</div>
<ul>
<li><p>To enforce these constraints, we introduce <strong>Lagrange multipliers</strong> <span class="math notranslate nohighlight">\( \lambda_0, \lambda_1, \lambda_2, \dots \)</span>, leading to the <strong>Lagrangian</strong> (also called the objective function):</p>
<div class="math notranslate nohighlight">
\[
  J[p] = - \sum_k p_k \log p_k - \lambda_0 \left( \sum_k p_k - 1 \right) - \lambda_1 \left( \sum_k p_k \, x_k - \langle x \rangle \right) - \lambda_2 \left( \sum_k p_k \, y_k - \langle y \rangle \right) - \dots
  \]</div>
</li>
<li><p>To maximize <span class="math notranslate nohighlight">\( J[p] \)</span>, we take its functional derivative with respect to <span class="math notranslate nohighlight">\( p_k \)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\delta J}{\delta p_k} = - (1 + \log p_k) - \lambda_0 - \lambda_1 x_k - \lambda_2 y_k - \dots = 0.
\]</div>
<div class="math notranslate nohighlight">
\[
\log p_k = - 1 - \lambda_0 - \lambda_1 x_k - \lambda_2 y_k - \dots
\]</div>
<div class="math notranslate nohighlight">
\[
p_k = e^{-1 - \lambda_0} e^{- \lambda_1 x_k} e^{- \lambda_2 y_k} \dots
\]</div>
<ul class="simple">
<li><p>Since <span class="math notranslate nohighlight">\( e^{-1 - \lambda_0} \)</span> is simply a constant normalization factor, we define <span class="math notranslate nohighlight">\(Z = e^{1+\lambda_0}\)</span> and arrie at final expression for probability distribution:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p_k = \frac{1}{Z} e^{- \lambda_1 x_k} e^{- \lambda_2 y_k} \dots
\]</div>
<div class="math notranslate nohighlight">
\[
Z = \sum_k e^{- \lambda_1 x_k- \lambda_2 y_k-...}
\]</div>
<ul class="simple">
<li><p><strong>Interperation of MaxEnt</strong></p>
<ul>
<li><p>The probability distribution takes an <strong>exponential form</strong> in the constrained variables <span class="math notranslate nohighlight">\( x_k, y_k, \dots \)</span>.</p></li>
<li><p>The normalization constant <span class="math notranslate nohighlight">\( Z \)</span> (also called the <strong>partition function</strong>) ensures that the probabilities sum to 1.</p></li>
<li><p>The Lagrange multipliers <span class="math notranslate nohighlight">\( \lambda_1, \lambda_2, \dots \)</span> encode the specific constraints imposed on the system.</p></li>
<li><p>This result is fundamental in <strong>statistical mechanics</strong>, where it leads to <strong>Boltzmann distributions</strong>, and in <strong>machine learning</strong>, where it underpins <strong>maximum entropy models</strong>.</p></li>
</ul>
</li>
</ul>
<div class="important admonition">
<p class="admonition-title"><strong>MaxEnt: Maximize Entropy Subject to Constraints</strong>  </p>
<ul>
<li><p><strong>Step 1: Construct the Entropy Functional with Constraints on variables <span class="math notranslate nohighlight">\(x\)</span>, <span class="math notranslate nohighlight">\(y\)</span>, </strong></p>
<div class="math notranslate nohighlight">
\[
  J[p] = - \sum_k p_k \log p_k - \lambda_0 \left( \sum_k p_k - 1 \right) - \lambda_1 \left( \sum_k p_k \, x_k - \langle x \rangle \right) - \lambda_2 \left( \sum_k p_k \, y_k - \langle y \rangle \right) - \dots
  \]</div>
</li>
<li><p><strong>Step 2: Maximize <span class="math notranslate nohighlight">\(J[p] \)</span> by Setting <span class="math notranslate nohighlight">\(\delta J[p] = 0 \)</span></strong></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p_k = \frac{1}{Z} e^{- \lambda_1 x_k- \lambda_2 y_k...} 
\]</div>
<div class="math notranslate nohighlight">
\[
Z = \sum_k e^{- \lambda_1 x_k- \lambda_2 y_k-...}
\]</div>
<ul>
<li><p><strong>Step 3: Solve for <span class="math notranslate nohighlight">\(\lambda_i \)</span> using the constraints</strong></p>
<div class="math notranslate nohighlight">
\[
  \sum_k p_k \, x_k= \langle x \rangle, \quad \sum_k p_k \, y_k= \langle y \rangle, \, ...
  \]</div>
</li>
</ul>
</div>
</section>
<section id="application-maxent-biased-die-example">
<h2>Application MaxEnt: Biased Die Example<a class="headerlink" href="#application-maxent-biased-die-example" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>If we are given a fair die MaxENt would predict <span class="math notranslate nohighlight">\(p_i=1/6\)</span> as there are no constraints.</p></li>
<li><p>But suppose we are given a biased die the average outcome of which is rolling on average a number <span class="math notranslate nohighlight">\( \langle x \rangle = 5.5 \)</span>. The entropy function to maximize becomes:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ J[p_1, p_2, ..] = - \sum p_i \log p_i - \lambda \left( \sum_i p_i - 1 \right) - B \left( \sum_i p_i x_i - 5.5 \right). \]</div>
<ul class="simple">
<li><p>Solving the variational equation, we find that the optimal probability distribution follows an exponential form:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ p_i = \frac{e^{- B x_i}}{Z}, \]</div>
<ul class="simple">
<li><p>where <span class="math notranslate nohighlight">\( Z \)</span> is the partition function ensuring normalization:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ Z = \sum_{i=1}^{6} e^{- B x_i}. \]</div>
<ul class="simple">
<li><p>To determine <span class="math notranslate nohighlight">\( B \)</span>, we use the constraint <span class="math notranslate nohighlight">\( \langle x \rangle = 5.5 \)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ \sum_{i=1}^{6} x_i \frac{e^{- B x_i}}{Z} = 5.5. \]</div>
<ul class="simple">
<li><p>This equation can be solved numerically for <span class="math notranslate nohighlight">\( B \)</span>. In many cases, Newtons method or other root-finding techniques can be employed to find the exact value of <span class="math notranslate nohighlight">\( B \)</span>. This distribution resembles the Boltzmann factor in statistical mechanics, where higher outcomes are exponentially less probable.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title"><strong>Newtons Method for Optimization</strong></p>
<ul class="simple">
<li><p>Used to find the root <span class="math notranslate nohighlight">\( B^* \)</span> of <span class="math notranslate nohighlight">\( f(B) = 0 \)</span> via iterative refinement.</p></li>
<li><p>Given an initial guess <span class="math notranslate nohighlight">\( B_0 \)</span>, we update using:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
B_{n+1} = B_n - \frac{f(B_n)}{f'(B_n)}
\]</div>
<p><strong>Derivation via Taylor Expansion</strong></p>
<ul class="simple">
<li><p>Expanding <span class="math notranslate nohighlight">\( f(B) \)</span> around <span class="math notranslate nohighlight">\( B_n \)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(B) \approx f(B_n) + f'(B_n)(B - B_n)
\]</div>
<ul class="simple">
<li><p>Setting <span class="math notranslate nohighlight">\( f(B) = 0 \)</span>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
B = B_n - \frac{f(B_n)}{f'(B_n)}
\]</div>
<p><strong>Application to Optimization</strong></p>
<ul class="simple">
<li><p>For minimization, set <span class="math notranslate nohighlight">\( f(B) = g'(B) \)</span> and apply:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
B_{n+1} = B_n - \frac{g'(B_n)}{g''(B_n)}
\]</div>
<ul class="simple">
<li><p>This efficiently finds critical points and is useful in <strong>MaxEnt</strong> problems.</p></li>
</ul>
</div>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.optimize</span><span class="w"> </span><span class="kn">import</span> <span class="n">newton</span>

<span class="k">def</span><span class="w"> </span><span class="nf">partition_function</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">B</span> <span class="o">*</span> <span class="n">x</span><span class="p">))</span>

<span class="k">def</span><span class="w"> </span><span class="nf">expected_value</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">partition_function</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">B</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">Z</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span>

<span class="k">def</span><span class="w"> </span><span class="nf">objective_function</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">expected_value</span><span class="p">(</span><span class="n">B</span><span class="p">)</span> <span class="o">-</span> <span class="mf">5.5</span>

<span class="k">def</span><span class="w"> </span><span class="nf">objective_derivative</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">partition_function</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">B</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">Z</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span> <span class="o">*</span> <span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>

<span class="c1"># Find optimal B using Newton&#39;s method</span>
<span class="n">B_opt</span> <span class="o">=</span> <span class="n">newton</span><span class="p">(</span><span class="n">objective_function</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">fprime</span><span class="o">=</span><span class="n">objective_derivative</span><span class="p">)</span>

<span class="c1"># Compute final probability distribution</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="n">Z</span> <span class="o">=</span> <span class="n">partition_function</span><span class="p">(</span><span class="n">B_opt</span><span class="p">)</span>
<span class="n">optimal_p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">B_opt</span> <span class="o">*</span> <span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="n">Z</span>

<span class="c1"># Print results</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Optimal B: </span><span class="si">{</span><span class="n">B_opt</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Optimized probability distribution:&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">optimal_p</span><span class="p">,</span> <span class="mi">1</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;P(</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">) = </span><span class="si">{</span><span class="n">p</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="c1"># Plot the resulting probability distribution</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">optimal_p</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;royalblue&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Die Outcome&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Probability&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Optimized MaxEnt Probability Distribution for a Biased Die&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s2">&quot;y&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Optimal B: -1.086963747049358
Optimized probability distribution:
P(1) = 0.0029
P(2) = 0.0086
P(3) = 0.0255
P(4) = 0.0755
P(5) = 0.2238
P(6) = 0.6637
</pre></div>
</div>
<img alt="../_images/54bd061c7e3dbcf3b2f9fde71e6f6b5c78866fa80d42791464e9e20686a2ff6b.png" src="../_images/54bd061c7e3dbcf3b2f9fde71e6f6b5c78866fa80d42791464e9e20686a2ff6b.png" />
</div>
</div>
<div class="tip admonition">
<p class="admonition-title"><strong>Physical constriants on energy</strong></p>
<ul class="simple">
<li><p>If the system is in thermal contact with a heat bath at temperature <span class="math notranslate nohighlight">\( T \)</span>, energy is allowed to fluctuate. The mean energy <span class="math notranslate nohighlight">\( \langle E \rangle = U \)</span> however should be constant hence we use it as constraint:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ J = -\sum_k p_k \log p_k - \lambda \left( \sum_k p_k - 1 \right) - \beta \left( \sum_k p_k E_k - U \right). \]</div>
<ul class="simple">
<li><p>Solving, we obtain the Boltzmann distribution:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[ p_k = \frac{e^{-\beta E_k}}{Z}, \]</div>
</div>
</section>
<section id="relative-entropy">
<h2>Relative Entropy<a class="headerlink" href="#relative-entropy" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>We mentioned that in MaxEnt derivation we maximized entropy relative to an underlying assumption of equal-probability microstates. We make this idea precise here</p></li>
<li><p>Consider example of 1D brownian particle starting at <span class="math notranslate nohighlight">\(x_0 = 0\)</span> and diffusing freely. Its probability distribution after time <span class="math notranslate nohighlight">\(t\)</span> follows a Gaussian:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
p(x, t) = \frac{1}{\sqrt{2\pi \sigma^2}} e^{-\frac{x^2}{4Dt}}
\]</div>
<ul class="simple">
<li><p>The <strong>Shannon entropy</strong> of this distribution is given by:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
S(t) = -\int p(x, t) \log p(x, t) \, dx.
\]</div>
<ul class="simple">
<li><p>Evaluating the integral yields nice compact formulla showing that entropy grows with time as molecule diffuse and sparead all over the container.</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
S(t) = \frac{1}{2} \log (4\pi e Dt).
\]</div>
<p><strong>Problem: Grid Dependence of Shannon Entropy</strong></p>
<ul class="simple">
<li><p>All is good but if we tried to evaluate the integral we would run into serious problem!</p></li>
<li><p>Also how to interpret integral expression in terms of binary yes/no quesionts?</p></li>
<li><p>A major issue with Shannon entropy is that it <strong>depends on the choice of units</strong>. If we refine the grid by choosing a smaller <span class="math notranslate nohighlight">\(\Delta x\)</span>, the computed entropy does not converge to a well-defined valueit diverges! This makes it unsuitable for studying entropy change in diffusion.</p></li>
<li><p>To avoid this issue, one can instead use <strong>relative entropy</strong> (Kullback-Leibler divergence), which remains well-defined and independent of discretization.</p></li>
</ul>
<div class="important admonition">
<p class="admonition-title"><strong>Relative Entropy</strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \sum_x P(x) \ln \frac{P(x)}{Q(x)}
\]</div>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \int P(x) \ln \frac{P(x)}{Q(x)} \, dx.
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(Q\)</span> <strong>reference probability</strong> distribution</p></li>
<li><p><span class="math notranslate nohighlight">\(P\)</span> <strong>true probability</strong> distribution or the one we are using/observing.</p></li>
</ul>
</div>
<ul class="simple">
<li><p>The Kullback-Leibler (KL) divergence, or relative entropy, measures <strong>how much information is lost when using a reference distribution Q</strong></p></li>
<li><p><strong>KL is non-negative and equals zero if and only if <span class="math notranslate nohighlight">\(P = Q \)</span> everywhere.</strong></p></li>
<li><p>KL divergence is widely used in statistical mechanics, information theory, machine learning and thermodynamics as a measure of information loss when approximating one distribution with another.</p></li>
</ul>
<div class="tip dropdown admonition">
<p class="admonition-title"><strong>Flashback to Random Walk and LDT</strong>  </p>
<ul>
<li><p><a class="reference external" href="https://dpotoyan.github.io/Statmech4ChemBio/1_stats/Probabilities_Counting.html#large-deviation-theory">We have already encountered relative entropy in the random walk problem!</a></p></li>
<li><p>There, we derived what is known as the <strong>Large Deviation Theory (LDT)</strong> expression, which shows that fluctuations are concentrated around the minima of <span class="math notranslate nohighlight">\( I(f) \)</span>a function that initially seemed mysterious but proved to be fundamental:</p>
<div class="math notranslate nohighlight">
\[
  P_N (f) \sim e^{-N I(f)}.
  \]</div>
</li>
<li><p>Now, we recognize that this function is actually the <strong>relative entropy</strong> between the empirical and true probability distributions as <span class="math notranslate nohighlight">\( N \)</span> increases:</p>
<div class="math notranslate nohighlight">
\[
  I(f) = f_+ \log \frac{f_+}{p_+} + f_- \log \frac{f_-}{p_-} = D(f || p)
  \]</div>
<div class="math notranslate nohighlight">
\[
  P_N (f) \sim e^{-N D(f || p)}
  \]</div>
</li>
<li><p>Thus, we see that <strong>relative entropy quantifies how unlikely it is to observe an empirical fraction <span class="math notranslate nohighlight">\( f \)</span> deviating from the true probability <span class="math notranslate nohighlight">\( p \)</span></strong>. The larger the relative entropy <span class="math notranslate nohighlight">\( D(f || p) \)</span>, the less likely it is to observe such a deviation!</p></li>
</ul>
</div>
</section>
<section id="assymetry-of-kl-and-irreversibility">
<h2>Assymetry of KL and irreversibility<a class="headerlink" href="#assymetry-of-kl-and-irreversibility" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>Given two normal distributions:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
P(x) = \mathcal{N}(\mu_1, \sigma_1^2), \quad Q(x) = \mathcal{N}(\mu_2, \sigma_2^2),
\]</div>
<ul class="simple">
<li><p>We can compute KL divergence analytically showing that the function is assymteric</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \ln \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}.
\]</div>
<div class="tip dropdown admonition">
<p class="admonition-title"><strong>KL Divergence between two Gaussians</strong></p>
<p class="rubric"><strong>Derivation of KL Divergence Between Two Gaussians</strong></p>
<p>Given two normal distributions:</p>
<div class="math notranslate nohighlight">
\[
P(x) = \mathcal{N}(\mu_1, \sigma_1^2), \quad Q(x) = \mathcal{N}(\mu_2, \sigma_2^2),
\]</div>
<p>the <strong>Kullback-Leibler (KL) divergence</strong> is defined as:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \int_{-\infty}^{\infty} p(x) \ln \frac{p(x)}{q(x)} \,dx.
\]</div>
<p><strong>Step 1: Write Out the Gaussian PDFs</strong>
The probability density functions of the two Gaussians are:</p>
<div class="math notranslate nohighlight">
\[
P(x) = \frac{1}{\sqrt{2\pi \sigma_1^2}} e^{-\frac{(x - \mu_1)^2}{2\sigma_1^2}},
\]</div>
<div class="math notranslate nohighlight">
\[
Q(x) = \frac{1}{\sqrt{2\pi \sigma_2^2}} e^{-\frac{(x - \mu_2)^2}{2\sigma_2^2}}.
\]</div>
<p>Taking their ratio:</p>
<div class="math notranslate nohighlight">
\[
\frac{P(x)}{Q(x)} = \frac{\sigma_2}{\sigma_1} \exp \left[ \frac{(x - \mu_2)^2}{2\sigma_2^2} - \frac{(x - \mu_1)^2}{2\sigma_1^2} \right].
\]</div>
<p>Taking the natural logarithm:</p>
<div class="math notranslate nohighlight">
\[
\ln \frac{P(x)}{Q(x)} = \ln \frac{\sigma_2}{\sigma_1} + \frac{(x - \mu_2)^2}{2\sigma_2^2} - \frac{(x - \mu_1)^2}{2\sigma_1^2}.
\]</div>
<p><strong>Step 2: Compute the Expectation <span class="math notranslate nohighlight">\( \mathbb{E}_P[\ln P(x)/Q(x)] \)</span></strong></p>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \mathbb{E}_P \left[ \ln \frac{P(x)}{Q(x)} \right] = \int P(x) \ln \frac{P(x)}{Q(x)} \,dx.
\]</div>
<p>Since expectation under <span class="math notranslate nohighlight">\( P(x) \)</span> means integrating with <span class="math notranslate nohighlight">\( P(x) \)</span>, we evaluate the three terms separately.</p>
<ol class="arabic">
<li><p><strong>First term:</strong><br />
$<span class="math notranslate nohighlight">\(
\mathbb{E}_P \left[ \ln \frac{\sigma_2}{\sigma_1} \right] = \ln \frac{\sigma_2}{\sigma_1}
\)</span>$
since it is a constant.</p></li>
<li><p><strong>Second term:</strong><br />
Using the property of a Gaussian expectation <span class="math notranslate nohighlight">\( \mathbb{E}_P [(x - \mu_1)^2] = \sigma_1^2 \)</span>,</p>
<div class="math notranslate nohighlight">
\[
   \mathbb{E}_P \left[ \frac{(x - \mu_1)^2}{2\sigma_1^2} \right] = \frac{1}{2}.
   \]</div>
</li>
<li><p><strong>Third term:</strong><br />
Expanding <span class="math notranslate nohighlight">\( (x - \mu_2)^2 \)</span>,</p>
<div class="math notranslate nohighlight">
\[
   (x - \mu_2)^2 = (x - \mu_1 + \mu_1 - \mu_2)^2.
   \]</div>
<p>Taking expectation under <span class="math notranslate nohighlight">\( P(x) \)</span>,</p>
<div class="math notranslate nohighlight">
\[
   \mathbb{E}_P \left[ \frac{(x - \mu_2)^2}{2\sigma_2^2} \right] = \frac{1}{2\sigma_2^2} \left( \sigma_1^2 + (\mu_1 - \mu_2)^2 \right).
   \]</div>
</li>
</ol>
<p><strong>Step 3: Final KL Divergence Formula</strong></p>
<p>Combining all terms, we get:</p>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P || Q) = \ln \frac{\sigma_2}{\sigma_1} + \frac{\sigma_1^2 + (\mu_1 - \mu_2)^2}{2\sigma_2^2} - \frac{1}{2}.
\]</div>
</div>
<ul class="simple">
<li><p>Computing <strong>KL divergence</strong> between two gaussians describing diffusion at times <span class="math notranslate nohighlight">\( t_1 \)</span> and <span class="math notranslate nohighlight">\( t_2 \)</span>, where their variances are <span class="math notranslate nohighlight">\( \sigma_1^2 = 2D t_1 \)</span> and <span class="math notranslate nohighlight">\( \sigma_2^2 = 2D t_2 \)</span> results in:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
D(p_1 \| p_2) = \frac{1}{2} \left( \frac{t_1}{t_2} - 1 + \log \frac{t_2}{t_1} \right)
\]</div>
<ul class="simple">
<li><p>For a <strong>diffusion process</strong>, if we compare the <strong>forward evolution</strong>of diffusion where variance is spreading over time <span class="math notranslate nohighlight">\(t_1=t\)</span> with the hypothetical <strong>reversed process</strong> where guassian contraints into a peak over time <span class="math notranslate nohighlight">\(t_2=T-t\)</span> we can see that:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
D_{\text{KL}}(P_{\text{forward}} || P_{\text{backward}}) &gt; 0.
\]</div>
<ul class="simple">
<li><p>This indicates that diffusion is an <strong>irreversible</strong> process in the absence of external driving forces (since it tends to increase entropy). In contrast, a time-reversed diffusion process (all particles contracting back into the initial state) would violate the second law of thermodynamics.</p></li>
<li><p>This statistical distinguishability of time-forward and time-reversed processes is often referred to the <strong>thermodynamic arrow of time</strong> showing that the forward flow of events is distinguishable from its reverse.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Define time points</span>
<span class="n">t_forward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">t_reverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>

<span class="c1"># Define probability distributions for forward and reverse processes</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">sigma_forward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">t_forward</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>  <span class="c1"># Diffusion spreads over time</span>
<span class="n">sigma_reverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">t_reverse</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">])</span>  <span class="c1"># Reverse &quot;contracts&quot; over time</span>

<span class="n">P_forward</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma_forward</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_forward</span><span class="p">)</span>
<span class="n">P_reverse</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="o">**</span><span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">sigma_reverse</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">)</span> <span class="o">*</span> <span class="n">sigma_reverse</span><span class="p">)</span>

<span class="c1"># Compute Kullback-Leibler divergence D_KL(P_forward || P_reverse)</span>
<span class="n">D_KL</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">P_forward</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">P_forward</span> <span class="o">/</span> <span class="n">P_reverse</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Plot the distributions and KL divergence</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="c1"># Plot forward and reverse distributions</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">P_forward</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">t_forward</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">t_forward</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Blues&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;P_forward&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">P_reverse</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">[</span><span class="n">t_reverse</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">t_reverse</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">x</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">,</span> <span class="n">origin</span><span class="o">=</span><span class="s1">&#39;lower&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;Reds&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;P_reverse&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Position&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Forward (Blue) vs Reverse (Red) Diffusion&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>  <span class="c1"># Forward arrow</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">arrow</span><span class="p">(</span><span class="mf">1.8</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">head_width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">head_length</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">fc</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">,</span> <span class="n">ec</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>  <span class="c1"># Reverse arrow</span>

<span class="c1"># Plot KL divergence over time</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">t_forward</span><span class="p">,</span> <span class="n">D_KL</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;$D_</span><span class="si">{KL}</span><span class="s1">(P_{\mathrm</span><span class="si">{forward}</span><span class="s1">} || P_{\mathrm</span><span class="si">{reverse}</span><span class="s1">})$&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;black&#39;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Time&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;KL Divergence&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Arrow of Time and Irreversibility&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<img alt="../_images/f43c4280d1a32119078073fd2872abb83914aed0d21a83b6d4b1518069b83d77.png" src="../_images/f43c4280d1a32119078073fd2872abb83914aed0d21a83b6d4b1518069b83d77.png" />
</div>
</div>
<section id="relative-entropy-in-machine-learning">
<h3>Relative Entropy in Machine learning<a class="headerlink" href="#relative-entropy-in-machine-learning" title="Permalink to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>If <span class="math notranslate nohighlight">\( Q(x) \)</span> <strong>assigns very low probability</strong> to a region where <span class="math notranslate nohighlight">\( P(x) \)</span> is high, the term <span class="math notranslate nohighlight">\( \log \frac{P(x)}{Q(x)} \)</span> becomes large, <strong>strongly penalizing <span class="math notranslate nohighlight">\( Q \)</span> for underestimating <span class="math notranslate nohighlight">\( P \)</span></strong>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\( Q(x) \)</span> <strong>is broader than <span class="math notranslate nohighlight">\( P(x) \)</span>, assigning extra probability mass to unlikely regions</strong>, this does not significantly affect <span class="math notranslate nohighlight">\( D_{\text{KL}}(P || Q) \)</span>, because <span class="math notranslate nohighlight">\( P(x) \)</span> is small in those regions.</p></li>
</ol>
<ul class="simple">
<li><p>This asymmetry explains why <strong>KL divergence is not a true distance metric</strong>. It penalizes <strong>underestimation</strong> of true probability mass much more than <strong>overestimation</strong>, making it particularly useful in <strong>machine learning</strong> where models are trained to avoid assigning near-zero probabilities to observed data.</p></li>
</ul>
<div class="cell tag_hide-input docutils container">
<details class="hide above-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell source</span>
<span class="expanded">Hide code cell source</span>
</summary>
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">ipywidgets</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">widgets</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ipywidgets</span><span class="w"> </span><span class="kn">import</span> <span class="n">interact</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.stats</span><span class="w"> </span><span class="kn">import</span> <span class="n">norm</span>

<span class="k">def</span><span class="w"> </span><span class="nf">plot_gaussians</span><span class="p">(</span><span class="n">mu1</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">sigma1</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">mu2</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sigma2</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="n">x_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>  <span class="c1"># Define spatial grid</span>
    <span class="n">P</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu1</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma1</span><span class="p">)</span>  <span class="c1"># First Gaussian</span>
    <span class="n">Q</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="n">mu2</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="n">sigma2</span><span class="p">)</span>  <span class="c1"># Second Gaussian</span>
    
    <span class="c1"># Avoid division by zero in KL computation</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">P</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">Q</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">D_KL_PQ</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">P</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">/</span> <span class="n">Q</span><span class="p">[</span><span class="n">mask</span><span class="p">]),</span> <span class="n">x_values</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>  <span class="c1"># D_KL(P || Q)</span>
    <span class="n">D_KL_QP</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">trapz</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span> <span class="o">/</span> <span class="n">P</span><span class="p">[</span><span class="n">mask</span><span class="p">]),</span> <span class="n">x_values</span><span class="p">[</span><span class="n">mask</span><span class="p">])</span>  <span class="c1"># D_KL(Q || P)</span>
    
    <span class="c1"># Plot the distributions</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$P(x) \sim \mathcal</span><span class="se">{{</span><span class="s1">N</span><span class="se">}}</span><span class="s1">(</span><span class="si">{</span><span class="n">mu1</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">sigma1</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$Q(x) \sim \mathcal</span><span class="se">{{</span><span class="s1">N</span><span class="se">}}</span><span class="s1">(</span><span class="si">{</span><span class="n">mu2</span><span class="si">}</span><span class="s1">,</span><span class="si">{</span><span class="n">sigma2</span><span class="o">**</span><span class="mi">2</span><span class="si">}</span><span class="s1">)$&#39;</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;dashed&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">x_values</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="s1">&#39;Difference between $P$ and $Q$&#39;</span><span class="p">)</span>
    
    <span class="c1"># Annotate KL divergences</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="sa">rf</span><span class="s1">&#39;$D_</span><span class="se">{{</span><span class="s1">KL</span><span class="se">}}</span><span class="s1">(P || Q) = </span><span class="si">{</span><span class="n">D_KL_PQ</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;blue&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="sa">rf</span><span class="s1">&#39;$D_</span><span class="se">{{</span><span class="s1">KL</span><span class="se">}}</span><span class="s1">(Q || P) = </span><span class="si">{</span><span class="n">D_KL_QP</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;red&#39;</span><span class="p">)</span>
    
    <span class="c1"># Labels and legend</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;$x$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Probability Density&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Interactive KL Divergence Between Two Gaussians&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="n">interact</span><span class="p">(</span><span class="n">plot_gaussians</span><span class="p">,</span> 
         <span class="n">mu1</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;1&#39;</span><span class="p">),</span>
         <span class="n">sigma1</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;1&#39;</span><span class="p">),</span>
         <span class="n">mu2</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=-</span><span class="mi">3</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;2&#39;</span><span class="p">),</span>
         <span class="n">sigma2</span><span class="o">=</span><span class="n">widgets</span><span class="o">.</span><span class="n">FloatSlider</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s1">&#39;2&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</details>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"version_major": 2, "version_minor": 0, "model_id": "6d369e87d6774eb2acae7bc8567a47af"}</script><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;function __main__.plot_gaussians(mu1=0, sigma1=1, mu2=1, sigma2=2)&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="problems">
<h2>Problems<a class="headerlink" href="#problems" title="Permalink to this heading">#</a></h2>
<section id="problem-1-compute-entropy-for-gas-partitioning">
<h3>Problem-1: Compute Entropy for gas partitioning<a class="headerlink" href="#problem-1-compute-entropy-for-gas-partitioning" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>A container is divided into two equal halves. It contains <strong>100 non-interacting gas particles</strong> that can freely move between the two sides. A macrostate is defined by the fraction of particles in the right half <span class="math notranslate nohighlight">\(f\)</span>.</p></li>
</ul>
<ol class="arabic simple">
<li><p><strong>Write down an exprssion for entropy S(f)</strong></p>
<ul class="simple">
<li><p>Consult the section on <a class="reference external" href="https://dpotoyan.github.io/Statmech4ChemBio/1_stats/Probabilities_Counting.html#random-walk">Random Walk and Combinatorics formula</a></p></li>
</ul>
</li>
<li><p><strong>Evaluate <span class="math notranslate nohighlight">\( S(f) \)</span> for:</strong></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( f_L = 0.1 \)</span> (10% left, 90% right)</p></li>
<li><p><span class="math notranslate nohighlight">\( f_L = 0.25 \)</span> (25% left, 75% right)</p></li>
<li><p><span class="math notranslate nohighlight">\( f_L = 0.5 \)</span> (50% left, 50% right)</p></li>
</ul>
</li>
<li><p><strong>Relate entropy to probability using Large Deviation Theory</strong> and answer the following questions:</p>
<ul class="simple">
<li><p>Which macrostate is most probable?</p></li>
<li><p>How does entropy influence probability?</p></li>
<li><p>Why are extreme fluctuations (e.g., <span class="math notranslate nohighlight">\( f = 0.1 \)</span>) unlikely?</p></li>
</ul>
</li>
</ol>
</section>
<section id="problem-2">
<h3>Problem-2<a class="headerlink" href="#problem-2" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Below we generate three 2D gaussians <span class="math notranslate nohighlight">\(P(x,y)\)</span> with varying degree of correltion betwene <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(y\)</span>. Run the code to visualize</p></li>
</ul>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>

<span class="c1"># Define mean values</span>
<span class="n">mu_x</span><span class="p">,</span> <span class="n">mu_y</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>  <span class="c1"># Mean of x and y</span>

<span class="c1"># Define standard deviations</span>
<span class="n">sigma_x</span><span class="p">,</span> <span class="n">sigma_y</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span>  <span class="c1"># Standard deviation of x and y</span>

<span class="c1"># Define different correlation coefficients</span>
<span class="n">correlations</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">]</span>  <span class="c1"># Varying degrees of correlation</span>

<span class="c1"># Generate and plot 2D Gaussian samples for different correlations</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">rho</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">correlations</span><span class="p">):</span>
    <span class="c1"># Construct covariance matrix</span>
    <span class="n">covariance_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">sigma_x</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="n">rho</span> <span class="o">*</span> <span class="n">sigma_x</span> <span class="o">*</span> <span class="n">sigma_y</span><span class="p">],</span>
                                   <span class="p">[</span><span class="n">rho</span> <span class="o">*</span> <span class="n">sigma_x</span> <span class="o">*</span> <span class="n">sigma_y</span><span class="p">,</span> <span class="n">sigma_y</span><span class="o">**</span><span class="mi">2</span><span class="p">]])</span>
    
    <span class="c1"># Generate samples from the 2D Gaussian distribution</span>
    <span class="n">samples</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="n">mu_x</span><span class="p">,</span> <span class="n">mu_y</span><span class="p">],</span> <span class="n">covariance_matrix</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    
    <span class="c1"># Plot scatter of samples</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">samples</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">samples</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;2D Gaussian with Correlation  = </span><span class="si">{</span><span class="n">rho</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Y&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<ul class="simple">
<li><p>Compute entropy using probability distributions <span class="math notranslate nohighlight">\(P(x,y), P(x|y=0), P(x)\)</span> and <span class="math notranslate nohighlight">\(P(y)\)</span></p></li>
<li><p>Compute relative entropy <span class="math notranslate nohighlight">\(D_{KL}(P(x,y)|| p(x) p(y))\)</span> which is known as <strong>Mutual Information</strong>. How can you interpret this quantity</p></li>
<li><p>You will need these functions. Also check out <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html"><code class="docutils literal notranslate"><span class="pre">scipy.stats.entropy</span></code></a></p></li>
</ul>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Task</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">numpy</span></code> Function</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Compute histogram for <span class="math notranslate nohighlight">\( P(x, y) \)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">numpy.histogram2d</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Compute histogram for <span class="math notranslate nohighlight">\( P(x) \)</span>, <span class="math notranslate nohighlight">\( P(y) \)</span></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">numpy.histogram</span></code></p></td>
</tr>
<tr class="row-even"><td><p>Normalize histograms to get probabilities</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">numpy.sum()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>Compute entropy manually</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">numpy.log()</span></code>, <code class="docutils literal notranslate"><span class="pre">numpy.sum()</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="problem-3-gambling-with-ten-sided-die">
<h3>Problem-3: Gambling with ten sided die<a class="headerlink" href="#problem-3-gambling-with-ten-sided-die" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Take a ten sided die described by random variable <span class="math notranslate nohighlight">\(X =1,2....10\)</span></p></li>
<li><p>Experiment shows that after many throughs the average number die shows is <span class="math notranslate nohighlight">\(E[x]=5\)</span> with variance <span class="math notranslate nohighlight">\(V[X] = 1.5\)</span>.</p></li>
<li><p>Determine probabilities of ten die sides <span class="math notranslate nohighlight">\(p(x)\)</span>. You can use the code for six sided die in this notebook. But remember there are now two constraints one on mean and one on variance!</p></li>
</ul>
</section>
<section id="problem-3-biased-random-walker-in-2d">
<h3>Problem-3 Biased Random walker in 2D<a class="headerlink" href="#problem-3-biased-random-walker-in-2d" title="Permalink to this heading">#</a></h3>
<p>A <strong>random walker</strong> moves on a <strong>2D grid</strong>, taking steps in one of four possible directions:</p>
<p>Each step occurs with <strong>unknown probabilities</strong>:</p>
<div class="math notranslate nohighlight">
\[
p_{\rightarrow}, p_{\leftarrow}, p_{\uparrow}, p_{\downarrow}\]</div>
<p>which satisfy the <strong>normalization condition</strong>:</p>
<div class="math notranslate nohighlight">
\[
p_{\rightarrow} + p_{\leftarrow} + p_{\uparrow} + p_{\downarrow} = 1.
\]</div>
<p>Experimental measurements indicate the <strong>expected displacement per step</strong>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[x] = p_{\rightarrow} - p_{\leftarrow} = \mu_x = 0.2, \quad
\mathbb{E}[y] = p_{\uparrow} - p_{\downarrow} = \mu_y = 0.1.
\]</div>
<p>Using the <strong>Maximum Entropy (MaxEnt) principle</strong>, determine the probabilities <span class="math notranslate nohighlight">\( p^* \)</span> by <strong>numerically solving an optimization problem</strong>.</p>
<ul class="simple">
<li><p>You will need <code class="docutils literal notranslate"><span class="pre">scipy.minimize(entropy,</span> <span class="pre">initial_guess,</span> <span class="pre">bounds=bounds,</span> <span class="pre">constraints=constraints,</span> <span class="pre">method='SLSQP')</span></code> to do the minimization. Check <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html">the documentation</a> to see how it works</p></li>
</ul>
</section>
<section id="problem-5-arrow-of-time-in-2d-diffusion">
<h3>Problem-5: Arrow of time in 2D diffusion<a class="headerlink" href="#problem-5-arrow-of-time-in-2d-diffusion" title="Permalink to this heading">#</a></h3>
<ol class="arabic">
<li><p><strong>Simulate 2D diffusion using a Gaussian distribution</strong></p>
<ul>
<li><p>Model diffusion in <strong>two dimensions</strong> with a probability distribution:</p>
<div class="math notranslate nohighlight">
\[
     P(x, y, t) = \frac{1}{4\pi D t} \exp\left(-\frac{x^2 + y^2}{4 D t}\right)
     \]</div>
</li>
<li><p>Generate samples at different time steps <span class="math notranslate nohighlight">\( t \)</span> using <strong><code class="docutils literal notranslate"><span class="pre">numpy.random.normal</span></code></strong> with time-dependent variance.</p></li>
</ul>
</li>
<li><p><strong>Compute the relative entropy as a function of time <span class="math notranslate nohighlight">\( S_{\text{rel}}(t) \)</span></strong></p>
<ul>
<li><p>Use <strong>relative entropy</strong> (Kullback-Leibler divergence) to compare the probability distributions at time <span class="math notranslate nohighlight">\( t \)</span> with a reference time <span class="math notranslate nohighlight">\( t_0 = 0.1 \)</span>:</p>
<div class="math notranslate nohighlight">
\[
     D_{\text{KL}}(P(x, y, t) || P(x, y, t_0))
     \]</div>
</li>
</ul>
</li>
<li><p><strong>Compare forward and reverse evolution of diffusion</strong></p>
<ul>
<li><p>Compute the relative entropy between <strong>forward</strong> (<span class="math notranslate nohighlight">\( t \to t + \Delta t \)</span>) and <strong>reverse</strong> (<span class="math notranslate nohighlight">\( t \to t - \Delta t \)</span>) diffusion distributions.</p></li>
<li><p>Quantify how diffusion leads to <strong>irreversible evolution</strong> by evaluating:</p>
<div class="math notranslate nohighlight">
\[
     D_{\text{KL}}(P_{\text{forward}} || P_{\text{reverse}})
     \]</div>
</li>
</ul>
</li>
<li><p><strong>Interpret the results</strong></p>
<ul class="simple">
<li><p>How does <strong>relative entropy change with time</strong>?</p></li>
<li><p>Why is the forward process distinguishable from the reverse process?</p></li>
<li><p>What does this tell us about the <strong>arrow of time</strong>?</p></li>
</ul>
</li>
</ol>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "DPotoyan/Statmech4ChemBio",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./1_stats"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Diffusion.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Diffusion</p>
      </div>
    </a>
    <a class="right-next"
       href="../2_thermo/intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Thermodynamics</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#surprise">Surprise</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#addititivity-of-information">Addititivity of Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#why-bit-base-two">Why bit (base two)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#shannon-entropy-and-information">Shannon Entropy and Information</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-micro-and-macro-states">Entropy, micro and macro states</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interpretations-of-entropy">Interpretations of Entropy</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-as-a-measure-of-information">1. Entropy as a Measure of Information</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#entropy-as-a-measure-of-uncertainty">2. Entropy as a Measure of Uncertainty</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#physical-and-thermodynamic-implications">3. Physical and Thermodynamic Implications</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#is-information-physical">Is Information Physical?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#maximum-entropy-maxent-principle">Maximum Entropy (MaxEnt) Principle</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application-maxent-biased-die-example">Application MaxEnt: Biased Die Example</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy">Relative Entropy</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#assymetry-of-kl-and-irreversibility">Assymetry of KL and irreversibility</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#relative-entropy-in-machine-learning">Relative Entropy in Machine learning</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#problems">Problems</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-1-compute-entropy-for-gas-partitioning">Problem-1: Compute Entropy for gas partitioning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-2">Problem-2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-gambling-with-ten-sided-die">Problem-3: Gambling with ten sided die</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-3-biased-random-walker-in-2d">Problem-3 Biased Random walker in 2D</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#problem-5-arrow-of-time-in-2d-diffusion">Problem-5: Arrow of time in 2D diffusion</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Davit Potoyan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=5b4479735964841361fd"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=5b4479735964841361fd"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>